{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Text Data with scikit-learn\n",
    "@ Sani Kamal, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Convert text to word count vectors with `CountVectorizer`.\n",
    "- Convert text to word frequency vectors with `TfidfVectorizer`.\n",
    "- Convert text to unique integers with `HashingVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Counts with CountVectorizer\n",
    "The `CountVectorizer` provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 0, 'human': 8, 'beings': 3, 'are': 2, 'born': 4, 'free': 7, 'and': 1, 'equal': 6, 'in': 9, 'dignity': 5, 'rights': 10}\n",
      "(1, 11)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[1 2 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# list of text documents\n",
    "text = [\"All human beings are born free and equal in dignity and rights.\"]\n",
    "\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "# print(vector)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 1 0 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# encode another document\n",
    "text2 = [\"born free and equal why\"]\n",
    "vector = vectorizer.transform(text2)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequencies with TfidfVectorizer\n",
    "\n",
    "`TF-IDF` calculate word frequencies. This is an acronym that stands for `Term Frequency - Inverse\n",
    "Document Frequency` which are the components of the resulting scores assigned to each word.\n",
    "- Term Frequency: This summarizes how often a given word appears within a document.\n",
    "- Inverse Document Frequency: This downscales words that appear a lot across documents.\n",
    "\n",
    "`TF-IDF` are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.\n",
    "\n",
    "The `TfidfVectorizer` will tokenize documents, learn the vocabulary and inverse document frequency weightings, and allow encode new documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 1, 'human': 13, 'beings': 5, 'are': 4, 'born': 6, 'free': 12, 'and': 2, 'equal': 11, 'in': 14, 'dignity': 9, 'rights': 18, 'they': 21, 'endowed': 10, 'with': 23, 'reason': 17, 'conscience': 8, 'should': 19, 'act': 0, 'towards': 22, 'one': 16, 'another': 3, 'spirit': 20, 'of': 15, 'brotherhood': 7}\n",
      "[1.40546511 1.40546511 1.         1.40546511 1.         1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.         1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511]\n",
      "(1, 24)\n",
      "[[0.         0.30099921 0.42832683 0.         0.21416342 0.30099921\n",
      "  0.30099921 0.         0.         0.30099921 0.         0.30099921\n",
      "  0.30099921 0.30099921 0.21416342 0.         0.         0.\n",
      "  0.30099921 0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# list of text documents\n",
    "text = [\"All human beings are born free and equal in dignity and rights.\",\n",
    "        \"They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.\"]\n",
    "\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "\n",
    "# encode document\n",
    "vector = vectorizer.transform([text[0]])\n",
    "\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing with HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20)\n",
      "[[-0.26726124  0.          0.         -0.26726124  0.         -0.53452248\n",
      "   0.          0.          0.          0.26726124  0.          0.26726124\n",
      "   0.26726124  0.          0.          0.          0.53452248  0.\n",
      "   0.26726124  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# list of text documents\n",
    "text = [\"All human beings are born free and equal in dignity and rights.\"]\n",
    "\n",
    "# create the transform\n",
    "vectorizer = HashingVectorizer(n_features=20)\n",
    "\n",
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
